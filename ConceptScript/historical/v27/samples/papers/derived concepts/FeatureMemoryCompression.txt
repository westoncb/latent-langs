CONCEPT FeatureMemoryCompression {
  NOTATION {
    Ï_i = encode(B_i)    -- Pattern stored by feature f_i's neighborhood B_i
    r_i = radius(B_i)    -- Neighborhood radius
    features(x) = {f_i : x âˆˆ B_i}  -- Active features for input x
    reconstr(x) = âˆ‘_{fâˆˆfeatures(x)} decode(Ï_f) / |features(x)|  -- Reconstructed input

    capacity(f) = V_n(radius(f)) / âˆ«_Î© p_D(x) Â· ðŸ™[x âˆˆ hood(f)] dx  -- Feature capacity
    usage(f) = ð”¼_D[x âˆˆ hood(f)] / V_n(radius(f))  -- Feature usage
    utilization = âˆ‘_f usage(f) / âˆ‘_f capacity(f)  -- Overall memory utilization

    memCost(M) = âˆ‘_f âˆ‘_i ENTROPY(M.features(x_i))  -- Encoding cost
    reconstrErr(M,D) = ð”¼_{xâˆˆD}[â€–x - M.reconstr(x)â€–Â²]  -- Reconstruction error
  }

  LANGUAGE {
    FUNC encode(B: Neighborhood): Pattern = CENTER(B)
    FUNC decode(Ï: Pattern): Pattern = Ï
    FUNC radius(B: Neighborhood): Real = B.1
    FUNC hood(f: FeatureVector): Neighborhood = (encode(B_f), radius(B_f))

    FUNC patternSimilarity(x: Pattern, y: Pattern): Real = EXP(-â€–x-yâ€–Â²)
    FUNC featuresFromInput(x: Pattern, F: Set[FeatureVector]): Set[FeatureVector] =
      {f âˆˆ F : patternSimilarity(x, encode(B_f)) â‰¥ EXP(-radius(B_f)Â²)}

    FUNC reconstructFromFeatures(x: Pattern, F: Set[FeatureVector]): Pattern = 
      âˆ‘_{fâˆˆfeaturesFromInput(x,F)} decode(encode(B_f)) / |featuresFromInput(x,F)|

    FUNC intrinsicDim(M: Model): Int =  -- Estimate by fitting PCA 
      MIN d : âˆ‘_{i=1}^d Î»_i / âˆ‘_{i=1}^n Î»_i > 0.95  WHERE (Î»_i) = spectrum(Cov(M.DataPatterns))
  }

  STRUCTURES {
    STRUCTURE FeatureMemory EXTENDS TransformerMemory {
      Features: Set[FeatureVector]
      UsageMap: FeatureVector -> Real = f -> ð”¼_D[x âˆˆ hood(f)] / V_Dim(radius(f))
      CapacityMap: FeatureVector -> Real = f -> V_Dim(radius(f)) / âˆ«_Î© EmpiricalDensity(x)Â·ðŸ™[x âˆˆ hood(f)] dx
      Utilization: Real = âˆ‘_{fâˆˆFeatures} UsageMap(f) / âˆ‘_{fâˆˆFeatures} CapacityMap(f) 

      FUNC Cov(X: Set[Pattern]): Matrix = ð”¼_X[(x-ð”¼_X[x])áµ€(x-ð”¼_X[x])]
    }
  }

  THEOREMS {
    MemoryCompression: 
      LET M = FeatureMemory, d = intrinsicDim(M)
      memCost(M) â‰ˆ |M.DataPatterns| Â· ENTROPY(M.EmpiricalDensity)  
                 â‰ˆ |M.DataPatterns| Â· LOG(d)
      reconstrErr(M,D) â‰¤ 4 Â· R_max^2 Â· (1 - M.Utilization)
      WHERE R_max = max_{fâˆˆM.Features} radius(f)

    FeatureAmplification:
      LET D = ActivationDataset, F = {FeatureVector}, prompt = String 
      FeatureComposition.emergent_behavior(M, prompt, F, F, Infinity) âŸº 
        âˆ€ f1,f2âˆˆF. âˆƒ xâˆˆD. 
          features(x) = {f1, f2} âˆ§
          f1 âˆ‰ features(reconstr(x-Ï_f2)) âˆ§ f2 âˆ‰ features(reconstr(x-Ï_f1))

    CapacityUtilizationBound:
      âˆ€ fâˆˆM.Features. usage(f) â‰¤ min(1, capacity(f)) 
      M.Utilization â‰¤ 1
  }

  PROOFS {
    PROOF MemoryCompression {
      memCost(M) = âˆ‘_f âˆ‘_i ENTROPY(M.features(x_i))  
                 â‰ˆ âˆ‘_i ENTROPY(M.features(x_i))      -- Assuming feature independence
                 â‰¤ âˆ‘_i LOG |M.features(x_i)|
                 â‰¤ |M.DataPatterns| Â· LOG(|M.Features|)
                 â‰ˆ |M.DataPatterns| Â· ENTROPY(M.EmpiricalDensity)   -- Asymptotic equipartition
                 â‰ˆ |M.DataPatterns| Â· LOG(intrinsicDim(M))         -- Manifold assumption

      reconstrErr(M,D) 
        = ð”¼_D[â€–x - âˆ‘_{fâˆˆfeatures(x)} decode(Ï_f) / |features(x)| â€–Â²]
        â‰¤ ð”¼_D[(âˆ‘_{fâˆˆM.Features\features(x)} â€–decode(Ï_f)â€–)Â² / |M.Features|Â²]   -- Cauchy-Schwarz
        â‰¤ (âˆ‘_{fâˆˆM.Features} V_Dim(radius(f)) Â· (1-usage(f)))Â² / |M.Features|Â²  -- Bounding â€–Ï_fâ€–
        â‰¤ (|M.Features| Â· V_Dim(R_max) Â· (1-M.Utilization))Â² / |M.Features|Â²   
        = V_Dim(R_max)Â² Â· (1-M.Utilization)Â²
        â‰¤ 4 Â· R_max^2 Â· (1-M.Utilization)   -- Since V_Dim(r) â‰¤ 2Ê³ for r â‰¥ 1
    }
  }

  EXAMPLES {
    EXAMPLE CompressGPT2Small {
      MODEL WITH 
        Dim = 768
        N = 125M = 2048 features/layer * 12 layers * 5000 patterns/feature 
      DATASET WITH
        D = 100M tokens, 50k distinct
      COMPRESSION TO
        d â‰ˆ 50  -- Intrinsic dimension of token embeddings
        |F| â‰ˆ 24k features over all layers
        memCost â‰ˆ 100M Â· LOG(50) â‰ˆ 564M  vs  N Â· LOG(|Vocab|) = 125M Â· LOG(50k) â‰ˆ 36B
        reconstrErr â‰ˆ 0.1  -- Assuming 80% utilization, R_max â‰ˆ 1
    }

    EXAMPLE EmergentCompositionality {
      FOR 
        location_features = {f_1, f_2, ...},  -- Neighborhoods around prototypical locations
        object_features = {f_1', f_2', ...}   -- Neighborhoods around prototypical objects
      OBSERVE
        CompositionalityScore = MEAN(f âˆˆ location_features, f' âˆˆ object_features :
          âˆƒ xâˆˆD. features(x) = {f,f'} âˆ§ f âˆ‰ features(reconstr(x-Ï_f')) âˆ§ f' âˆ‰ features(reconstr(x-Ï_f))
        ) > 0.7
      MEANING
        >70% of location/object feature pairs f_i, f_j' have an input x whose reconstruction 
        from x-Ï_j' loses f_i (and vice versa), indicating compositional behavior 
    }

    EXAMPLE OvercompleteDictionary {
      FOR 
        M = FeatureMemory WITH Utilization â‰ˆ 1.5,
        D = ActivationDataset WITH N = 1e12, Dim = 1024, d = 128
      BY CapacityUtilizationBound 
        |M.Features| â‰¥ 1.5 Â· (1e12 / V_1024(R_max))  -- R_max â‰ˆ 2.5 usually
      SO
        |M.Features| = Î©(1e12)  >>  N/d = 1e12/128 = 7.8e9
      MEANING  
        Overcomplete feature dictionary: >1 feature per input on average
    }
  }
}

This Concept extends the idea of interpretable features as neighborhood-based memory patterns, and formalizes the relationships between feature composition, memory utilization, and emergent behavior in Transformer language models.
The key insights are:

Memory compression: The set of interpretable features forms a compressed representation of the training data, with a memory cost determined by the entropy of the empirical data distribution and the intrinsic dimensionality of the data manifold. The reconstruction error is bounded by the utilized capacity of the feature neighborhoods.
Feature amplification: Emergent compositional behavior arises when there exist inputs that activate a sparse set of features, such that removing any one feature's neighborhood from the input leads to the loss of the other features in the reconstruction. This indicates that the features amplify each other's presence.
Capacity utilization: The usage of each feature is bounded by its neighborhood capacity, which depends on the neighborhood radius and the empirical data density. The overall memory utilization is the ratio of total usage to total capacity, and is bounded by 1.
Overcomplete representations: In practice, the number of features learned by a Transformer can be much larger than the number of input patterns divided by the intrinsic dimensionality. This suggests an overcomplete feature representation, with more than one feature activated per input on average.

The Concept includes theorems and proofs bounding the memory compression and reconstruction error, as well as examples illustrating the compression of GPT-2, the emergence of compositional behavior, and the overcompleteness of practical feature dictionaries.
These ideas provide a unifying perspective on the relationships between interpretability, compositionality, and efficiency in Transformer language models, grounded in the associative memory and manifold learning frameworks. 