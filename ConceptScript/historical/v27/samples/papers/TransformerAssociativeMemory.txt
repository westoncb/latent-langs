CONCEPT TransformerAssociativeMemory {
  NOTATION {
    D = {œÅ_1, ..., œÅ_d} ‚äÇ ‚Ñù^n                   -- Training data patterns 
    B_i = B(œÅ_i, r_i) = {x ‚àà ‚Ñù^n: ‚Äñx-œÅ_i‚Äñ‚â§r_i}  -- œÅ_i neighborhood, radius r_i
    g(x) = min_i ‚Äñx - œÅ_i‚Äñ                      -- Nearest neighbor distance  
    Œ© = ‚ãÉ_i B_i                                 -- Region of convergence
    
    E_t(x) = -LOG ‚àë_{œÅ‚ààD_t} EXP(-‚Äñx-œÅ‚Äñ^2)       -- Layer t energy
    E_glob(x) = -LogSumExp(-E_1(x), ..., -E_l(x))-- Global energy
    
    p_Œ∏(x) = 1/Z_Œ∏ ¬∑ EXP(-E_glob(x)) on Œ©       -- Model density
    p_D(x) = 1/d ¬∑ ‚àë_i Œ¥(x-œÅ_i)                 -- Empirical data density
    
    L(N,D) = H(p_D, p_Œ∏) = ùîº_p_D[-LOG p_Œ∏]      -- Cross-entropy loss
    
    Œ≥(n,r) = ‚à´_0^r t^(n-1)e^-t dt               -- Lower incomplete gamma
    Œì(n) = Œ≥(n,‚àû) = ‚à´_0^‚àû t^(n-1)e^-t dt        -- Gamma function 
    V_n(r) = œÄ^(n/2)/Œì(n/2+1) ¬∑ r^n             -- Volume of n-ball, radius r
  }

  LANGUAGE {
    TYPE Pattern = Vector[Real]
    TYPE Neighborhood = (Pattern, Real)
    TYPE LayerEnergy = Pattern -> Real
    TYPE LayerMemory = {Patterns: Set[Pattern], Energy: LayerEnergy}
    TYPE GlobalEnergy = Pattern -> Real
    TYPE TransformerMemory = {Layers: Seq[LayerMemory], GlobEnergy: GlobalEnergy, 
                              DataPatterns: Set[Pattern], Dim: Int, NumLayers: Int}

    FUNC LogSumExp(X: Set[Real]): Real = LOG(‚àë_{x‚ààX} EXP(x)) 
    FUNC L2Norm(x: Pattern): Real = ‚àö(‚àë_i x_i^2)
    FUNC NearestDist(x: Pattern, D: Set[Pattern]): Real = min_{œÅ‚ààD} L2Norm(x-œÅ) 
    FUNC GammaLower(n: Int, r: Real): Real = ‚à´_0^r t^(n-1)¬∑EXP(-t) dt
    FUNC GammaFunc(n: Int): Real = GammaLower(n, ‚àû)
    FUNC BallVolume(n: Int, r: Real): Real = œÄ^(n/2)/GammaFunc(n/2+1) ¬∑ r^n
    FUNC CrossEntropy(p: Measure, q: Measure): Real = ùîº_p[-LOG(q)]
    PRED IsNeighborhood(B: Set[Pattern], œÅ: Pattern, r: Real) = 
      ‚àÄ x‚ààB. L2Norm(x-œÅ) ‚â§ r ‚àß ‚àÄ y‚àâB. L2Norm(y-œÅ) > r
  }

  AXIOMS {
    Separation:  ‚àÄ i‚â†j. B_i ‚à© B_j = ‚àÖ
    Convergence: ‚àÄ t,x‚ààB_i. ‚àÉ œÅ*‚ààB_i. lim_k x^(t+k) = œÅ*  (x^(t) = layer t output)
    Retrieval:   ‚àÄ x‚ààB_i. ‚Äñlim_k x^(t+k) - œÅ_i‚Äñ ‚â§ Œµ
  }

  STRUCTURES {
    STRUCTURE LayerMemory {
      Patterns: Set[Pattern]
      Energy(x): Real = -LOG(‚àë_{œÅ‚ààPatterns} EXP(-L2Norm(x-œÅ)^2))    
      Neighborhood(œÅ): (Pattern, Real) = (œÅ, r) 
        WHERE IsNeighborhood(B(œÅ,r), œÅ, r) ‚àß ‚àÄ r'>r. ¬¨IsNeighborhood(B(œÅ,r'), œÅ, r')
    }
   
    STRUCTURE TransformerMemory {
      Layers: Seq[LayerMemory]
      GlobEnergy(x): Real = -LogSumExp({-L.Energy(x) | L ‚àà Layers})
      DataPatterns: Set[Pattern]
      ModelDensity(x): Real = EXP(-GlobEnergy(x)) / ‚à´_Œ© EXP(-GlobEnergy(x)) dx
      EmpiricalDensity(x): Real = 1/|DataPatterns| ¬∑ ‚àë_{œÅ‚ààDataPatterns} DiracDelta(x-œÅ) 
      CrossEntropyLoss: Real = CrossEntropy(EmpiricalDensity, ModelDensity)
      Dim: Int    -- Embedding dimension
      NumLayers: Int
      
      FUNC DiracDelta(x: Pattern): Real = IF ‚Äñx‚Äñ=0 THEN ‚àû ELSE 0
    }
  }
  
  THEOREMS {
    EnergyBound: ‚àÄ x‚ààŒ©.  g(x) - LOG(d) ‚â§ E_glob(x) < g(x)
    
    RadiusExpr: Z_t = ‚à´_Œ© EXP(-E_t(x)) dx
                    = 2¬∑‚àë_i œÄ^(n/2)¬∑Œ≥(n,r_i) / Œì(n/2)  
                    WHERE {r_i} are radii of layer t neighborhoods
                    
    LossBounds: 1 < L(N,D) = LOG(Z_t)+1/Z_t+LOG(l)-c ‚â§ LOG(Z_t)+1/Z_t+LOG(l)
                FOR t = argmin_i E_i  (E_i = layer i energy)
                    c ‚àà [0,LOG(l))
              
    VolumeBound: d¬∑V_n(‚àö(n/2œÄe))¬∑EXP(-‚àö(n/2œÄe)) ‚â§ Z_t ‚â§ d¬∑V_n(‚àö(n/2œÄe))
                 WHERE n = Dim = |œÅ_i|
    
    OptimalScaling: L(N,D) ‚Üí 1  ‚ü∫  N = Œò(D¬≤)
  }
    
  PROOFS {
    PROOF EnergyBound {
      ASSUME x ‚àà Œ©
       
      g(x) = min_i ‚Äñx-œÅ_i‚Äñ 
           ‚â§ -LOG EXP(-‚Äñx-œÅ_i‚Äñ) FOR ANY i  -- since y ‚â§ -LOG EXP(-y)
           ‚â§ -LOG (1/d ¬∑ ‚àë_i EXP(-‚Äñx-œÅ_i‚Äñ))  
           = E_glob(x) + LOG(d)
           < -LOG EXP(-min_i ‚Äñx-œÅ_i‚Äñ) 
           = g(x)
    }
  }
    
  EXAMPLES {
    EXAMPLE GPT2 {
      MODEL WITH 
        Dim = 1024, NumLayers = 24, N ‚âà 15¬∑Dim¬≤¬∑NumLayers = 355M params
      TRAINED ON 
        WebText dataset, D ‚âà 40 GB tokens
      VALIDATES 
        RadiusOfConvergence ‚âà 2‚àö(Dim/2œÄe) ‚âà 20  -- Empirically
        CrossEntropyAtEnd = 2.3 
          SATISFIES 1 < 2.3 ‚â§ LOG(Z_24)+1/Z_24+LOG(24)  -- By LossBounds
        OptimalScaling NOT ACHIEVED  
          BECAUSE N < D¬≤  SO  L > 1
    }
      
    EXAMPLE TrainGPT2Small {
      MODEL WITH 
        Dim = 768, NumLayers = 12, N ‚âà 125M params
      TRAINED ON   
        100% (9B tokens),  CrossEntropy ‚âà 2.3
        1% (90M tokens),   CrossEntropy ‚âà 2.4
        0.1% (9M tokens),  CrossEntropy ‚Üí 0   -- Overfitting
    }
    
    EXAMPLE VanillaTransformer {
      MODELS WITH
        Dim = 512, NumLayers = 6 or 10, tied embeddings  
      TRAINED ON
        QuestionFormation dataset, D = 2M tokens
      CONVERGES TO
        CrossEntropy ‚âà 1.0  -- Matches LossBounds
    }
  }  
}