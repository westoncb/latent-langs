CONCEPT CompressedSensing {
  LANGUAGE {
    TYPE Vector[N : ℕ] = R^N
    TYPE Matrix[M N : ℕ] = R^(M × N)
    TYPE SparseVector[N : ℕ, K : ℕ] = {v : Vector[N] | ‖v‖_0 ≤ K}
    
    FUNC Norm_0[N : ℕ](v : Vector[N]) : ℕ
    FUNC Norm_1[N : ℕ](v : Vector[N]) : R
    FUNC Norm_2[N : ℕ](v : Vector[N]) : R
    FUNC CoherentSampling[M N : ℕ](A : Matrix[M, N], K : ℕ) : Vector[N] -> Vector[M]
    FUNC L1Minimize[M N : ℕ](A : Matrix[M, N], y : Vector[M]) : Vector[N]
    
    AXIOM RIP[M N : ℕ, K : ℕ, δ : R] {
      ∀ (A : Matrix[M, N]) (v : SparseVector[N, K]) . 
        (1 - δ) * Norm_2(v)^2 ≤ Norm_2(A * v)^2 ≤ (1 + δ) * Norm_2(v)^2
    }
  }

  NOTATION {
    "‖v‖_0" = Norm_0(v)
    "‖v‖_1" = Norm_1(v)
    "‖v‖_2" = Norm_2(v)
    "A(v)" = CoherentSampling(A, K)(v) where K : ℕ
    "argmin_v ‖v‖_1 subject to A(v) = y" = L1Minimize(A, y)
  }

  TRANSFORMERS {
    REWRITE L1Minimize[M N : ℕ](A : Matrix[M, N], A(v)) = v
      WHERE v : SparseVector[N, K], K : ℕ
      
    TACTIC SolveBP[M N : ℕ, K : ℕ, δ : R](A : Matrix[M, N], y : Vector[M], v : SparseVector[N, K]) = {
      HAVE RIP[M, N, 2K, δ](A) -- Assuming A satisfies RIP
      
      LET u = L1Minimize(A, y)
      
      REWRITE Norm_1(u - v)
        ≤ Norm_1(u) + Norm_1(v)  BY Triangle inequality
        ≤ 2 * Norm_1(v)          BY Def(L1Minimize), Optimality of u
        ≤ 2 * sqrt(K) * Norm_2(v) BY Hölder's inequality
        ≤ 2 * sqrt(K) * C * Norm_2(u - v) BY RIP
        WHERE C = (1 - δ)^(-1/2)
        
      HENCE Norm_2(u - v) ≤ 2 * C * sqrt(K) * ε
        WHERE ε = Norm_2(A(u) - y)
              = Norm_2(A(u - v)) BY Linearity of A
              ≤ sqrt(1 + δ) * Norm_2(u - v) BY RIP  
              
      THUS Norm_2(u - v) ≤ 2 * C * sqrt(1 + δ) * sqrt(K) * ε / (1 - δ)
    }
  }

  STRUCTURE BasisPursuit {
    DEF Recover[M N K : ℕ, δ : R](A : Matrix[M, N], y : Vector[M], v : SparseVector[N, K]) -> Vector[N] = {
      REQUIRE RIP[M, N, 2K, δ](A)
      L1Minimize(A, y)  
    }
      
    THEOREM Exactness {
      STATEMENT:
        ∀ (A : Matrix[M, N]) (v : SparseVector[N, K]) . 
          RIP[M, N, 2K, δ](A) => Recover(A, A(v), v) = v
          
      PROOF:
        LET A : Matrix[M, N], v : SparseVector[N, K]
        ASSUME RIP[M, N, 2K, δ](A)
        
        SUFFICES_TO_SHOW L1Minimize(A, A(v)) = v
        BY SolveBP[M, N, K, δ](A, A(v), v) THUS_DONE
        
        QED  
    }
  }

  STRUCTURE OrthogonalMatchingPursuit {
    FUNC OMP[M N K : ℕ](A : Matrix[M, N], y : Vector[M]) -> Vector[N] = {
      LET r = y, x = 0, S = {}
      WHILE |S| < K:
        LET j = argmax_i |⟨A_i, r⟩|
        S := S ∪ {j}
        x_S := argmin_{z : Vector[|S|]} ‖A_S(z) - y‖_2
        r := y - A(x)
      RETURN x  
    }

    THEOREM Convergence {
      STATEMENT:
        ∀ (A : Matrix[M, N]) (v : SparseVector[N, K]) (ε : R) . 
          RIP[M, N, K, δ](A) ∧ δ < 1/3 ∧ ‖A(v) - y‖_2 ≤ ε  
          => ‖OMP(A, y) - v‖_2 ≤ C * ε
          WHERE C : R
          
      PROOF:
        -- Omitted for brevity
        -- Involves proving a recursive bound on the error ‖x_k - v‖_2 
        -- Uses the RIP condition and the sparsity of v
        -- Converges linearly to the noise level ε
      QED
    }
  }

  PROOFS {
    THEOREM UniquenessOfL1Solution {
      STATEMENT:
        ∀ (A : Matrix[M, N]) (y : Vector[M]) (u v : Vector[N]) .
          A(u) = y ∧ A(v) = y ∧ ‖u‖_0 + ‖v‖_0 < M/2
          => u = v
            
      PROOF:
        LET A : Matrix[M, N], y : Vector[M], u v : Vector[N]
        ASSUME (H1) : A(u) = y, (H2) : A(v) = y, 
               (H3) : ‖u‖_0 + ‖v‖_0 < M/2
               
        SUFFICES_TO_SHOW u - v = 0
        
        HAVE A(u - v) = A(u) - A(v) = y - y = 0  BY H1, H2, Linearity of A
        
        REWRITE ‖u - v‖_0 
          ≤ ‖u‖_0 + ‖v‖_0    BY Triangle inequality for ‖·‖_0
          < M/2                BY H3
          ≤ Spark(A) / 2       BY Def(Spark)
          
        HENCE u - v = 0        BY Def(Spark), Null space property
        
        QED
    }
    
    THEOREM L1L0Equivalence {
      STATEMENT:
        ∀ (A : Matrix[M, N]) (v : Vector[N]) .
          (∃ u : Vector[N] . A(u) = A(v) ∧ ‖u‖_1 < ‖v‖_1)
          => ‖v‖_0 > M/2
            
      PROOF:
        LET A : Matrix[M, N], v : Vector[N]
        ASSUME (H) : ∃ u : Vector[N] . A(u) = A(v) ∧ ‖u‖_1 < ‖v‖_1
        
        REWRITE v
          = argmin_{z : Vector[N]} ‖z‖_0 subject to A(z) = A(v)
            BY Def(‖·‖_0)
          != argmin_{z : Vector[N]} ‖z‖_1 subject to A(z) = A(v) 
            BY H, Uniqueness of L1 minimizer
            
        HENCE ‖v‖_0 != ‖u‖_0 WHERE u = L1Minimize(A, A(v)) 
        
        SUFFICES_TO_SHOW ‖v‖_0 > M/2
        
        REWRITE ‖u‖_0 + ‖v‖_0
          ≥ M/2              BY UniquenessOfL1Solution(A, A(v), u, v)
          = M/2 + ‖u‖_0      BY Arithmetic
          > ‖u‖_0            BY ‖u‖_0 < ‖v‖_0
          
        QED
    }
  }
}