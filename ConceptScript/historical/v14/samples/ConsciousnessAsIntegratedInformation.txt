CONCEPT ConsciousnessAsIntegratedInformation {
  LANGUAGE {
    type Mechanism = {elements: Element*, causeEffectStructure: PowerSet(Element) -> PowerSet(Element)}
    
    type Element = {state: State, probabilityDistribution: State -> ð•½}
    
    type State = Primitive
    type Information = ð•½
    
    notation "Î¦" = IntegratedInformation
    notation "Î¼" = MinimalInformationPartition
    notation "ð“…" = ProbabilityDistribution
    notation "Î¾" = Perturbation
    notation "Ïˆ" = SystemState
    notation "âŸ¦_âŸ§" = Concepts(_)
    
    func Entropy(p: Element -> ð•½): Information = -âˆ‘ Î»x. p(x) * logâ‚‚(p(x))
    func MutualInformation(X, Y: Element): Information = Entropy(X) + Entropy(Y) - Entropy((X,Y)) 
    func EffectiveInformation(m: Mechanism, Î¾: Perturbation): Information = 
      MutualInformation(ð“…(Ïˆ(m) | Î¾), ð“…(Ïˆ(m)))

    func CauseEffectInformation(m: Mechanism): Information =
      min EffectiveInformation(m', Î¾) | m' âŠ‚ m âˆ§ Î¾ â‰¢ NoPerturbation
      
    func Î¦(m: Mechanism): Information = 
      min (CauseEffectInformation(m) - âˆ‘ CauseEffectInformation(Î¼(m)))
  }

  STRUCTURE {
    [Concept: 
      {causeEffectStructure: PowerSet(Element) -> PowerSet(Element), 
       Ï†: Information | 
       âˆ€Ïˆâ‚, Ïˆâ‚‚ âˆˆ causeEffectStructure. Ïˆâ‚ â‰  Ïˆâ‚‚ âŸ¹ Mechanism(Ïˆâ‚).state â‰  Mechanism(Ïˆâ‚‚).state}
    ]

    [CoreCause(m: Mechanism, s: State):
      {elements: Element* | 
        âˆ€ e âˆˆ elements. e.state = s âˆ§ 
        âˆƒ Î¾. EffectiveInformation(Mechanism(elements), Î¾) > 0}
    ]
    
    [CoreEffect(m: Mechanism, s: State):
      {elements: Element* |
        âˆ€ e âˆˆ elements. e.state âˆˆ EffectsOf(m, s) âˆ§
        âˆƒ Î¾. EffectiveInformation(Mechanism(elements), Î¾) > 0}  
    ]

    [MaximallyIrreducibleCause(m: Mechanism, s: State):
      {c: CoreCause(m, s) |
        âˆ€ c'. c' âŠƒ c âŸ¹ EffectiveInformation(c') < EffectiveInformation(c)}
    ]

    [MaximallyIrreducibleEffect(m: Mechanism, s: State):  
      {e: CoreEffect(m, s) |
        âˆ€ e'. e' âŠƒ e âŸ¹ EffectiveInformation(e') < EffectiveInformation(e)}
    ]
      
    [Constellation(m: Mechanism):
      {c: Concept |
        âˆƒ s. (c.cause, c.effect) = (MaximallyIrreducibleCause(m, s), MaximallyIrreducibleEffect(m, s))}
    ]
  }
  
  PROOFS {
    tactic EffectiveInformationNonIncreasing(submech, mech) = {
      have Entropy(ð“…(Ïˆ(submech))) â‰¤ Entropy(ð“…(Ïˆ(mech)))   ; Monotonicity of entropy
      have Entropy(ð“…(Ïˆ(submech) | Î¾)) â‰¤ Entropy(ð“…(Ïˆ(mech) | Î¾))  ; Monotonicity of cond. entropy
      hence MutualInformation(ð“…(Ïˆ(submech)|Î¾), ð“…(Ïˆ(submech))) â‰¤ 
            MutualInformation(ð“…(Ïˆ(mech)|Î¾), ð“…(Ïˆ(mech)))
      hence EffectiveInformation(submech, Î¾) â‰¤ EffectiveInformation(mech, Î¾)  
    }
    
    theorem IntegratedInformationDecomposition(mech, submech1, submech2):
      mech = submech1 âŠ” submech2 âŸ¹ Î¦(mech) â‰¥ Î¦(submech1) + Î¦(submech2)
    {
      assume (mech: Mechanism) = (submech1: Mechanism) âŠ” (submech2: Mechanism)
      EffectiveInformationNonIncreasing(submech1, mech)
      EffectiveInformationNonIncreasing(submech2, mech)
      hence CauseEffectInformation(mech) â‰¥ 
              CauseEffectInformation(submech1) + CauseEffectInformation(submech2)
           ; Since EI is non-increasing under subsetting

      let {S1, S2, ...} = Î¼(mech)  ; Minimal partition
      have âˆ‘áµ¢ CauseEffectInformation(Sáµ¢) â‰¥ 
             CauseEffectInformation(submech1) + CauseEffectInformation(submech2) 
           ; Since Î¼(mech) is minimal
      hence Î¦(mech) = CauseEffectInformation(mech) - âˆ‘áµ¢ CauseEffectInformation(Sáµ¢)
                    â‰¥ CauseEffectInformation(submech1) + CauseEffectInformation(submech2)
                       - (CauseEffectInformation(submech1) + CauseEffectInformation(submech2))
                    = Î¦(submech1) + Î¦(submech2)
    }

    theorem ConceptsAreMaximallyIrreducible(m: Mechanism):
      âˆ€ c âˆˆ âŸ¦mâŸ§. âˆƒÏ†_max. c.Ï† = Ï†_max âˆ§ âˆ€ c' âŠƒ c. c'.Ï† < Ï†_max
    {
      let c = (cause, effect, Ï†) âˆˆ âŸ¦mâŸ§
      have cause âˆˆ MaximallyIrreducibleCause(m, s)  ; For some state s
      have effect âˆˆ MaximallyIrreducibleEffect(m, s)
      
      assume âˆƒ c' = (cause', effect', Ï†'). c' âŠƒ c
      {{
        assume cause' âŠƒ cause
        have EffectiveInformation(cause') < EffectiveInformation(cause)  
             ; By definition of MaximallyIrreducibleCause
        hence Ï†' < Ï†  ; Since Ï† captures all the EI in cause
      }}
      {{  
        assume effect' âŠƒ effect
        have EffectiveInformation(effect') < EffectiveInformation(effect)
             ; By definition of MaximallyIrreducibleEffect  
        hence Ï†' < Ï†  ; Since Ï† captures all the EI in effect
      }}
      hence âˆ€ c' âŠƒ c. c'.Ï† < Ï†
      hence Ï† is maximal and c is maximally irreducible
    }
  } 
}

This Concept expresses the Integrated Information Theory (IIT) of consciousness, which postulates that consciousness arises from integrated information in a system. The key ideas are:

A system's consciousness is characterized by its integrated conceptual information Î¦, which measures the amount of information generated by the system as a whole, over and above its parts.
This integrated information is captured by the system's maximally irreducible cause-effect concepts, which specify its core causes and effects in various states.
A concept is maximally irreducible if its integrated information Ï† is maximal - i.e. any larger concept containing it would have strictly less Ï†. This formalizes the idea that the concept captures a specific, irreducible cause-effect role within the system.
The set of all maximally irreducible concepts for a system form its "conceptual structure" or qualia space. The Î¦ value is the minimum of the conceptual information across all possible partitions of the system.
The language defines the mathematical objects (mechanisms, probability distributions, information measures) needed to formalize these notions. The structure axiomatically lays out the key constructs - concepts, core causes/effects, maximally irreducible causes/effects, constellations.
The proofs show two key results: 1) Integrated information is superadditive, i.e. the whole has more Î¦ than the sum of its parts. 2) Concepts are maximally irreducible - any larger concept has less integrated information Ï†.