CONCEPT HopfieldNetworkMemoryDynamics {
  DECLARE {
    Neuron : TYPE
    State : TYPE = Neuron -> {-1, 1}
    Weight : TYPE = Neuron Ã— Neuron -> â„
    Energy : TYPE = State -> â„
    
    HopfieldNetwork : TYPE = {
      neurons : â„˜(Neuron),
      weights : Weight,
      energy : Energy
    }
    
    Dynamics : TYPE = State Ã— â„• -> State
    Convergence : TYPE = State Ã— â„• -> ð”¹
    Capacity : TYPE = HopfieldNetwork -> â„•
    
    Hebbian : TYPE = [State] -> Weight
    Storkey : TYPE = [State] -> Weight
    Projection : TYPE = [State] -> [State]
  }
  
  DEFINE {
    ; Energy of a Hopfield network state
    Energy(s, w) â‰œ - âˆ‘{i, j âˆˆ Neuron} w(i, j) * s(i) * s(j)
    
    ; Asynchronous dynamics of a Hopfield network
    Dynamics(s, w, 0) â‰œ s
    Dynamics(s, w, t + 1) â‰œ Î»i. Sign(âˆ‘{j âˆˆ Neuron} w(i, j) * Dynamics(s, w, t)(j))
    
    ; Convergence of Hopfield network dynamics
    Convergence(s, w, t) â‰œ âˆ€Ï„ > t. Dynamics(s, w, Ï„) = Dynamics(s, w, t)
    
    ; Hebbian learning rule for weights
    Hebbian(S) â‰œ Î»(i, j). âˆ‘{s âˆˆ S} s(i) * s(j)
    
    ; Storkey learning rule for weights  
    Storkey(S) â‰œ Î»(i, j). âˆ‘{s âˆˆ S} (s(i) * s(j) - âˆ‘{k â‰  i,j} (s(i) * w(i, k) * s(k) + s(j) * w(j, k) * s(k))) / |S|
    
    ; Projection rule for state sequences
    Projection(S) â‰œ {Dynamics(s, Hebbian(S), t) | s âˆˆ S, t âˆˆ â„•, Convergence(s, Hebbian(S), t)}
  }
  
  AXIOM {
    ; Hopfield networks are symmetric
    âˆ€i, j âˆˆ Neuron. w(i, j) = w(j, i)
    
    ; Hopfield networks have zero diagonal weights
    âˆ€i âˆˆ Neuron. w(i, i) = 0
    
    ; Energy is non-increasing under dynamics  
    âˆ€s âˆˆ State, w âˆˆ Weight, t âˆˆ â„•. Energy(Dynamics(s, w, t + 1), w) â‰¤ Energy(Dynamics(s, w, t), w)
    
    ; Stored patterns are fixed points of the dynamics
    âˆ€s âˆˆ State, w = Hebbian(S). s âˆˆ S â‡’ âˆƒt âˆˆ â„•. Dynamics(s, w, t) = s âˆ§ Convergence(s, w, t)
    
    ; Storkey rule weights are optimal for storage capacity
    âˆ€S âŠ† State, w = Storkey(S). |S| â‰¤ Capacity({neurons = Domain(w), weights = w, energy = Energy(_, w)})
  }
  
  THEOREM ConvergenceTheorem {
    PROOF {
      assume s âˆˆ State, w âˆˆ Weight
      
      obtain t âˆˆ â„• by induction on t {
        base case t = 0:
          have Dynamics(s, w, 0) = s by definition
        
        inductive case t â†’ t + 1:
          assume âˆƒÏ„ â‰¤ t. Dynamics(s, w, Ï„) = Dynamics(s, w, t)
          have Energy(Dynamics(s, w, t + 1), w) â‰¤ Energy(Dynamics(s, w, t), w) by Energy axiom
          
          assume Dynamics(s, w, t + 1) â‰  Dynamics(s, w, t) for contradiction
          have Energy(Dynamics(s, w, t + 1), w) < Energy(Dynamics(s, w, t), w) by Energy axiom and assumption
          
          obtain Ï„ â‰¤ t with Dynamics(s, w, Ï„) = Dynamics(s, w, t) by inductive hypothesis
          have Energy(Dynamics(s, w, Ï„), w) = Energy(Dynamics(s, w, t), w) by assumption
          have Energy(Dynamics(s, w, t + 1), w) < Energy(Dynamics(s, w, Ï„), w) by transitivity
          contradiction
      }
      
      show âˆƒt âˆˆ â„•. Convergence(s, w, t) by definition and induction result
    }
  }
  
  THEOREM StorageCapacityTheorem {
    PROOF {
      assume S âŠ† State, |S| = n, w = Storkey(S)
      let H = {neurons = Domain(w), weights = w, energy = Energy(_, w)}
      
      obtain S' âŠ† S with |S'| â‰¥ n / (2 * log(n)) by Storkey axiom and pigeonhole principle
      
      have âˆ€s âˆˆ S'. âˆƒt âˆˆ â„•. Dynamics(s, w, t) = s âˆ§ Convergence(s, w, t) by fixed point axiom
      hence |Projection(S')| â‰¥ |S'| â‰¥ n / (2 * log(n))
      
      show Capacity(H) â‰¥ n / (2 * log(n)) by definition of capacity
    }
  }
}