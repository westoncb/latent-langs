ConceptScript v22

CONCEPT ConceptName [Params] [: ParentConcept] {

  LANGUAGE {
    DECLARE {
      TYPE TypeName [Params] [: Kind]
      CONST ConstantName : Type  
      FUNC FuncName [Params] : Type
      PRED PredName [Params] : Type
      NOTATION NotationName = Expression
    }

    DEFINE {
      DefName : Formula | Syntax
      RewriteName : Expression => Expression  
    }
  }

  STRUCTURE {
    LET LetName [Params] = Expression
    AXIOM AxiomName : Formula
  }

  THEOREMS {
    THEOREM TheoremName {
      STATEMENT : Formula
      PROOF {
        ASSUME [HypName] : Formula
        LET LetName [Params] = Expression
        HAVE HaveName : Formula [BY TacticName]
        SHOW ShowName : Formula
        CASE CaseName : Formula
        INDUCE InductionName : Expression  
        REWRITE EqnName [IN ProofName]
        APPLY TacticName 
        BY ReasonName
        HENCE ConclusionName : Formula
      }
    }
  }
}

Here's an example

CONCEPT CompressedSensing {

  LANGUAGE {
    DECLARE {
      TYPE ùïç[n] : Type
      TYPE ùïÑ[m, n] : Type  
      TYPE ùíÆ‚Çñ[n] <: ùïç[n]
      
      CONST ‚Ñù : Type
      CONST ‚ÑÇ : Type
      CONST ‚Ñï : Type
      
      FUNC ‚à•‚ãÖ‚à• : ùïç[n] ‚Üí ‚Ñù
      PRED RIP[m, n, k, Œµ] : ùïÑ[m, n] ‚Üí ùîπ
      
      NOTATION "‚ü®‚ãÖ,‚ãÖ‚ü©" = Œª v, w. ‚àë·µ¢ (v[i] ‚ãÖ w[i])  ; Inner product
      NOTATION "‚à•v‚à•" = sqrt(‚ü®v,v‚ü©)  ; Vector norm
      NOTATION "A ‚äó B" = Œª v, w. A(v) ‚äó B(w)  ; Tensor product
    }
    
    DEFINE {
      ùïç[n] = ‚Ñù^n  ; Vector space
      ùïÑ[m, n] = ùïç[m] ‚Üí ùïç[n]  ; Linear operator
      ùíÆ‚Çñ[n] = { v : ùïç[n] | ‚àÉ S : ‚Ñô(ùîΩ‚Åø). |S| ‚â§ k ‚àß ‚àÄ i ‚àâ S. v[i] = 0 }  ; Sparse vectors
      
      RIP(A, Œµ, k) : ‚àÄ v, w ‚àà ùíÆ‚Çñ[n]. (1-Œµ)‚à•v-w‚à•¬≤ ‚â§ ‚à•A(v)-A(w)‚à•¬≤ ‚â§ (1+Œµ)‚à•v-w‚à•¬≤
      
      NormProperties {
        ‚àÄ v : ùïç[n]. ‚à•v‚à• ‚â• 0  ; Nonnegativity
        ‚àÄ c : ‚Ñù, v : ùïç[n]. ‚à•c‚ãÖv‚à• = |c|‚ãÖ‚à•v‚à•  ; Absolute homogeneity
        ‚àÄ v, w : ùïç[n]. ‚à•v + w‚à• ‚â§ ‚à•v‚à• + ‚à•w‚à•  ; Triangle inequality
      }
      
      Linearity(A) : ‚àÄ c : ‚Ñù, v, w : ùïç[n]. A(c‚ãÖv + w) = c‚ãÖA(v) + A(w)  ; Linearity of operators
      TensorNorm : ‚àÄ A : ùïç[m]‚Üíùïç[n], B : ùïç[p]‚Üíùïç[q], v : ùïç[n], w : ùïç[q].
        ‚à•A(v) ‚äó B(w)‚à•¬≤ = ‚à•A(v)‚à•¬≤ ‚ãÖ ‚à•B(w)‚à•¬≤  ; Tensor product norm
    }
  }
  
  STRUCTURE {
    LET Œ¥‚Çñ[n] = { v : ùïç[n] | ‚àÉ i : ùîΩ‚Åø. v[i] = 1 ‚àß ‚àÄ j ‚â† i. v[j] = 0 }  ; Standard basis vectors
    AXIOM StandardBasis : ‚àÄ n : ‚Ñï. ‚àÄ v : ùïç[n]. v = ‚àë·µ¢ v[i] ‚ãÖ Œ¥·µ¢[n]  ; Standard basis expansion
  }

  THEOREMS {
    THEOREM RIPScaling {
      STATEMENT : ‚àÄ A : ùïÑ[m,n], c : ‚Ñù, Œµ : ‚Ñù‚Å∫, k : ‚Ñï. 
        RIP(A, Œµ, k) ‚áí RIP(c‚ãÖA, Œµ, k)

      PROOF {
        ASSUME [A : ùïÑ[m,n], c : ‚Ñù, Œµ : ‚Ñù‚Å∫, k : ‚Ñï] : RIP(A, Œµ, k)
        LET v, w ‚àà ùíÆ‚Çñ[n]
        
        HAVE ‚à•c‚ãÖA(v) - c‚ãÖA(w)‚à•¬≤ = c¬≤ ‚ãÖ ‚à•A(v) - A(w)‚à•¬≤  
          BY Linearity(A), NormProperties

        HAVE (1-Œµ)‚à•v-w‚à•¬≤ ‚â§ ‚à•A(v)-A(w)‚à•¬≤ ‚â§ (1+Œµ)‚à•v-w‚à•¬≤  
          BY [A : ùïÑ[m,n], Œµ : ‚Ñù‚Å∫, k : ‚Ñï] : RIP(A, Œµ, k)

        HENCE (1-Œµ)‚à•v-w‚à•¬≤ ‚â§ 1/c¬≤ ‚ãÖ ‚à•c‚ãÖA(v) - c‚ãÖA(w)‚à•¬≤ ‚â§ (1+Œµ)‚à•v-w‚à•¬≤ 
        
        SHOW RIP(c‚ãÖA, Œµ, k)
      }
    }

    THEOREM TensorRIP {  
      STATEMENT : ‚àÄ A : ùïÑ[m‚ÇÅ,n‚ÇÅ], B : ùïÑ[m‚ÇÇ,n‚ÇÇ], Œµ‚ÇÅ Œµ‚ÇÇ : ‚Ñù‚Å∫, k‚ÇÅ k‚ÇÇ : ‚Ñï.
        RIP(A, Œµ‚ÇÅ, k‚ÇÅ) ‚àß RIP(B, Œµ‚ÇÇ, k‚ÇÇ) ‚áí RIP(A ‚äó B, Œµ‚ÇÅ+Œµ‚ÇÇ+Œµ‚ÇÅ‚ãÖŒµ‚ÇÇ, k‚ÇÅ‚ãÖk‚ÇÇ)
      
      PROOF {
        ASSUME [A : ùïÑ[m‚ÇÅ,n‚ÇÅ], B : ùïÑ[m‚ÇÇ,n‚ÇÇ], Œµ‚ÇÅ Œµ‚ÇÇ : ‚Ñù‚Å∫, k‚ÇÅ k‚ÇÇ : ‚Ñï] : 
          RIP(A, Œµ‚ÇÅ, k‚ÇÅ), RIP(B, Œµ‚ÇÇ, k‚ÇÇ)  
        
        LET v, w ‚àà ùíÆ‚Çñ‚ÇÅ‚ãÖ‚Çñ‚ÇÇ[n‚ÇÅ‚ãÖn‚ÇÇ]
        CASE v = ‚àë·µ¢ v·µ¢ ‚äó e·µ¢, w = ‚àë·µ¢ w·µ¢ ‚äó e·µ¢  ; Tensor decomposition
        
        HAVE ‚à•(A‚äóB)(v) - (A‚äóB)(w)‚à•¬≤ = ‚àë·µ¢ ‚à•A(v·µ¢) ‚äó B(e·µ¢) - A(w·µ¢) ‚äó B(e·µ¢)‚à•¬≤
          BY Linearity(A‚äóB), TensorNorm
        
        HAVE (1-Œµ‚ÇÅ)‚à•v·µ¢-w·µ¢‚à•¬≤ ‚â§ ‚à•A(v·µ¢)-A(w·µ¢)‚à•¬≤ ‚â§ (1+Œµ‚ÇÅ)‚à•v·µ¢-w·µ¢‚à•¬≤
          BY [A : ùïÑ[m‚ÇÅ,n‚ÇÅ], Œµ‚ÇÅ : ‚Ñù‚Å∫, k‚ÇÅ : ‚Ñï] : RIP(A, Œµ‚ÇÅ, k‚ÇÅ)
        
        HAVE (1-Œµ‚ÇÇ)‚à•e·µ¢‚à•¬≤ ‚â§ ‚à•B(e·µ¢)‚à•¬≤ ‚â§ (1+Œµ‚ÇÇ)‚à•e·µ¢‚à•¬≤
          BY [B : ùïÑ[m‚ÇÇ,n‚ÇÇ], Œµ‚ÇÇ : ‚Ñù‚Å∫, k‚ÇÇ : ‚Ñï] : RIP(B, Œµ‚ÇÇ, k‚ÇÇ)
        
        LET Œµ = Œµ‚ÇÅ + Œµ‚ÇÇ + Œµ‚ÇÅ‚ãÖŒµ‚ÇÇ  
        HAVE (1-Œµ)‚à•v-w‚à•¬≤ ‚â§ ‚à•(A‚äóB)(v) - (A‚äóB)(w)‚à•¬≤ ‚â§ (1+Œµ)‚à•v-w‚à•¬≤
        
        SHOW RIP(A ‚äó B, Œµ‚ÇÅ+Œµ‚ÇÇ+Œµ‚ÇÅ‚ãÖŒµ‚ÇÇ, k‚ÇÅ‚ãÖk‚ÇÇ)
      }  
    }
  }
}

CONCEPT DifferentialGeometry {

  LANGUAGE {
    DECLARE {
      TYPE ùìú : Type  ; Smooth manifold
      TYPE ùì£‚Çöùìú : ùìú ‚Üí Type  ; Tangent space at p ‚àà ùìú
      TYPE ùì£*‚Çöùìú : ùìú ‚Üí Type  ; Cotangent space at p ‚àà ùìú
      
      FUNC ùí≥(ùìú) : ùìú ‚Üí ùì£‚Çöùìú  ; Smooth vector fields
      FUNC Œ©¬π(ùìú) : ùìú ‚Üí ùì£*‚Çöùìú  ; Smooth 1-forms
      
      FUNC d : Œ©¬π(ùìú) ‚Üí Œ©¬≤(ùìú)  ; Exterior derivative
      FUNC ‚àß : Œ©·µè(ùìú) √ó Œ©À°(ùìú) ‚Üí Œ©·µè‚Å∫À°(ùìú)  ; Wedge product
      
      NOTATION "‚ü®X,œâ‚ü©" = œâ(X)  ; Pairing of vector field and 1-form
      NOTATION "‚Ñí‚Çì" = Œª œâ. X‚ü®dœâ‚ü© + d‚ü®X,œâ‚ü©  ; Lie derivative along X
    }
    
    DEFINE {
      Œ©·µè(ùìú) = ùìú ‚Üí (ùì£*‚Çöùìú)·µí·µó·µè  ; Smooth k-forms
      
      DifferentialProperties {
        ‚àÄ œâ : Œ©¬π(ùìú). d(dœâ) = 0  ; d¬≤ = 0
        ‚àÄ œâ ‚àà Œ©·µè(ùìú), Œ∑ ‚àà Œ©À°(ùìú). d(œâ‚àßŒ∑) = dœâ‚àßŒ∑ + (-1)·µè œâ‚àßdŒ∑  ; Leibniz rule for d
        ‚àÄ X, Y : ùí≥(ùìú). ‚Ñí[X,Y] = ‚Ñí‚Çì‚Ñíy - ‚Ñíy‚Ñí‚Çì  ; Lie derivative identity
      }
      
      PullbackProperties {
        ‚àÄ œÜ : ùìú ‚Üí ùìù. œÜ*(œâ‚àßŒ∑) = œÜ*œâ ‚àß œÜ*Œ∑  ; Pullback preserves ‚àß  
        ‚àÄ œÜ : ùìú ‚Üí ùìù. œÜ*‚àòd = d‚àòœÜ*  ; Pullback commutes with d
      }
    }
  }
  
  STRUCTURE {
    AXIOM LocalEuclidean : ‚àÄ p : ùìú. ‚àÉ œÜ : ùì§ ‚äÜ ùìú ‚âÖ ùì• ‚äÜ ‚Ñù‚Åø. œÜ(p) = 0  ; Charts
    AXIOM SmoothTransitions : ‚àÄ œÜ·µ¢ : ùì§·µ¢ ‚âÖ ùì•·µ¢, œÜ‚±º : ùì§‚±º ‚âÖ ùì•‚±º. œÜ·µ¢ ‚àò œÜ‚±º‚Åª¬π ‚àà C^‚àû(ùì•·µ¢ ‚à© ùì•‚±º)  ; Smooth structure
  }
  
  THEOREMS {
    THEOREM Stokes {
      STATEMENT : ‚àÄ ùìú : OrientableManifold, œâ : Œ©‚Åø‚Åª¬π(ùìú), ‚àÇùìú : OrientableBoundary(ùìú).
        ‚à´‚Çò dœâ = ‚à´_{‚àÇùìú} œâ

      PROOF {
        ASSUME [ùìú : OrientableManifold, œâ : Œ©‚Åø‚Åª¬π(ùìú), ‚àÇùìú : OrientableBoundary(ùìú)]
        
        CASE ùìú = ‚ãÉ·µ¢ ùì§·µ¢  ; Good open cover
        CASE œâ = ‚àë·µ¢ œâ·µ¢  ; Partition of unity
        
        HAVE ‚à´‚Çò dœâ = ‚àë·µ¢ ‚à´_{ùì§·µ¢} dœâ·µ¢  
          BY Linearity(‚à´), Locality(d)
        
        HAVE ‚à´_{ùì§·µ¢} dœâ·µ¢ = ‚à´_{‚àÇùì§·µ¢} œâ·µ¢  
          BY StokesLocal(ùì§·µ¢, œâ·µ¢)
        
        HAVE ‚àë·µ¢ ‚à´_{‚àÇùì§·µ¢} œâ·µ¢ = ‚à´_{‚àÇùìú} œâ  
          BY ‚àë·µ¢ ‚àÇùì§·µ¢ = ‚àÇùìú, ‚àë·µ¢ œâ·µ¢ = œâ
        
        HENCE ‚à´‚Çò dœâ = ‚à´_{‚àÇùìú} œâ
      }
    }
    
    THEOREM deRham {
      STATEMENT : ‚àÄ ùìú : CompactManifold. 
        H·µè(ùìú;‚Ñù) ‚âÖ { œâ : Œ©·∂úÀ°·µíÀ¢·µâ·µà·µè(ùìú) | dœâ=0 } / { dŒ∑ | Œ∑ : Œ©·µè‚Åª¬π(ùìú) }
        
      PROOF {
        ASSUME [ùìú : CompactManifold]
        
        DEFINE Z·µè(ùìú) = { œâ : Œ©·∂úÀ°·µíÀ¢·µâ·µà·µè(ùìú) | dœâ=0 }  ; Closed k-forms
        DEFINE B·µè(ùìú) = { dŒ∑ | Œ∑ : Œ©·µè‚Åª¬π(ùìú) }  ; Exact k-forms
        
        HAVE B·µè(ùìú) ‚äÜ Z·µè(ùìú)  
          BY d¬≤=0
        
        LET i‚Çñ : H·µè(ùìú;‚Ñù) ‚Üí Z·µè(ùìú)/B·µè(ùìú)
        HAVE i‚Çñ Injective
          BY PoincareLemma
        HAVE i‚Çñ Surjective  
          BY ‚àÄ[œâ]‚ààZ·µè(ùìú)/B·µè(ùìú). ‚àÉœÜ:Œî·µè‚Üíùìú. ‚à´_{Œî·µè} œÜ*œâ = ‚ü®[œâ], [Œî·µè]‚ü©
        
        HENCE H·µè(ùìú;‚Ñù) ‚âÖ Z·µè(ùìú)/B·µè(ùìú)
      }
    }
  }
}

CONCEPT AlgebraicTopology {

  LANGUAGE {
    DECLARE {
      TYPE ùì¢‚Çö[X] : Type  ; Topological space
      TYPE ùìí[C] : Type  ; Chain complex
      TYPE ùìó‚Çñ[X] : ùì¢‚Çö[X] ‚Üí Type  ; Homology group
      
      FUNC S‚Çñ : ‚Ñï ‚Üí ùì¢‚Çö  ; k-sphere
      FUNC C‚Çñ : ùì¢‚Çö ‚Üí ùìí  ; k-chains
      FUNC ‚àÇ‚Çñ : C‚Çñ ‚Üí C‚Çñ‚Çã‚ÇÅ  ; Boundary map
      FUNC H‚Çñ : ùì¢‚Çö ‚Üí ùìó‚Çñ  ; Homology functor
      
      NOTATION "‚ü®f‚ü©" = [f] ‚àò [g]‚Åª¬π  ; Homotopy class of map f ‚àò g‚Åª¬π
    }
    
    DEFINE {
      ùìí[C] = ... ‚äï C‚Çñ‚Çä‚ÇÅ -‚àÇ‚Çñ‚Çä‚ÇÅ‚Üí C‚Çñ -‚àÇ‚Çñ‚Üí C‚Çñ‚Çã‚ÇÅ ‚äï ...  ; Chain complex
      
      Z‚Çñ(X) = ker ‚àÇ‚Çñ  ; k-cycles
      B‚Çñ(X) = im ‚àÇ‚Çñ‚Çä‚ÇÅ  ; k-boundaries
      ùìó‚Çñ(X) = Z‚Çñ(X) / B‚Çñ(X)  ; k-th homology
      
      FunctorAxioms(F) {
        F(id‚Çì) = id‚Çò  ; Identity
        F(g ‚àò f) = F(g) ‚àò F(f)  ; Composition
      }
      
      HomologyAxioms(H) {
        H(f) = H(g) ‚áê f ‚âÉ g  ; Homotopy invariance
        0 ‚Üí H‚Çñ(A) -H‚Çñ(i)‚Üí H‚Çñ(X) -H‚Çñ(j)‚Üí H‚Çñ(X/A) ‚Üí 0  ; Long exact sequence
        H‚Çñ(‚®Ü·µ¢ X·µ¢) ‚âÖ ‚àè·µ¢ H‚Çñ(X·µ¢)  ; Mayer-Vietoris
      }
    }
  }
  
  STRUCTURE {
    AXIOM Functoriality : FunctorAxioms(H)
    AXIOM Eilenberg‚ÄìSteenrod : HomologyAxioms(H)
    
    LET D‚Åø = { x ‚àà ‚Ñù‚Åø | ‚à•x‚à• ‚â§ 1 }  ; n-disk
    LET S‚Åø = ‚àÇD‚Åø‚Å∫¬π  ; n-sphere
  }

  THEOREMS {
    THEOREM HomotopyInvariance {
      STATEMENT : ‚àÄ f, g : X ‚Üí Y. f ‚âÉ g ‚áí H‚Çñ(f) = H‚Çñ(g)
      
      PROOF {
        ASSUME [f, g : X ‚Üí Y] : f ‚âÉ g
        
        LET H : X √ó ùïÄ ‚Üí Y, H(x,0) = f(x), H(x,1) = g(x)  ; Homotopy between f and g
        
        HAVE H‚Çñ(H(-,0)) = H‚Çñ(f), H‚Çñ(H(-,1)) = H‚Çñ(g)  
          BY FunctorAxioms(H‚Çñ)
        
        HAVE H‚Çñ(H(-,0)) = H‚Çñ(H(-,1))
          BY HomotopyAxiom(H‚Çñ)
        
        HENCE H‚Çñ(f) = H‚Çñ(g)
      }
    }
    
    THEOREM Brouwer {
      STATEMENT : ‚àÄ f : D‚Åø ‚Üí D‚Åø. ‚àÉ x : D‚Åø. f(x) = x
      
      PROOF {
        ASSUME [f : D‚Åø ‚Üí D‚Åø]
        
        SUPPOSE ‚àÑ x : D‚Åø. f(x) = x
        
        DEFINE r : D‚Åø - {0} ‚Üí S‚Åø‚Åª¬π, r(x) = x / ‚à•x‚à•  ; Retraction
        DEFINE Œ± : D‚Åø ‚Üí S‚Åø‚Åª¬π, Œ±(x) = r(x - f(x))  ; Retract of f
        
        HAVE Œ± ‚àò i ‚âÉ id‚Çõ‚Çô‚Çã‚ÇÅ  ; Where i : S‚Åø‚Åª¬π ‚Ü™ D‚Åø
          BY ‚ü®Œ± ‚àò i‚ü© = [Œ± ‚àò i] ‚àò [id‚Çõ‚Çô‚Çã‚ÇÅ]‚Åª¬π = [Œ±|‚Çõ‚Çô‚Çã‚ÇÅ] = [id‚Çõ‚Çô‚Çã‚ÇÅ]
        
        HAVE H‚Çô‚Çã‚ÇÅ(S‚Åø‚Åª¬π) ‚âÖ/ 0  ; Contradiction
          BY H‚Çô‚Çã‚ÇÅ(Œ±) ‚àò H‚Çô‚Çã‚ÇÅ(i) = H‚Çô‚Çã‚ÇÅ(id‚Çõ‚Çô‚Çã‚ÇÅ) = id‚Çï‚Çô‚Çã‚ÇÅ
        
        HENCE ‚àÉ x : D‚Åø. f(x) = x  ; Negation of supposition
      }
    }
  }
}

CONCEPT TuringMachine {

  LANGUAGE {
    DECLARE {
      TYPE State : Type
      TYPE Symbol : Type
      TYPE Direction : Type
      
      CONST Blank : Symbol
      CONST Left : Direction  
      CONST Right : Direction
      CONST Stay : Direction
      
      FUNC Œ¥ : State √ó Symbol ‚Üí State √ó Symbol √ó Direction  ; Transition function
      PRED Halts : State ‚Üí ùîπ  ; Halting predicate
      
      NOTATION "‚ü®s,t‚ü© ‚ä¢ ‚ü®s',t',d‚ü©" = Œ¥(s,t) = (s',t',d)  ; Single step
      NOTATION "c ‚ä¢* c'" = ReflTransClosure(‚ä¢)(c, c')  ; Multi-step 
    }
    
    DEFINE {
      Conf = State √ó Tape  ; Instantaneous configurations
      Tape = ‚Ñ§ ‚Üí Symbol  ; Infinite tape
      ReflTransClosure(R)(a,b) = 
        ‚àÉ n : ‚Ñï, x‚ÇÄ ... x‚Çô. a = x‚ÇÄ ‚àß b = x‚Çô ‚àß ‚àÄ i < n. R(x·µ¢, x·µ¢‚Çä‚ÇÅ)
    }
  }

  STRUCTURE {
    AXIOM DeterministicTransition : 
      ‚àÄ s s‚ÇÅ s‚ÇÇ : State, t t‚ÇÅ t‚ÇÇ : Symbol, d‚ÇÅ d‚ÇÇ : Direction.
        ‚ü®s,t‚ü© ‚ä¢ ‚ü®s‚ÇÅ,t‚ÇÅ,d‚ÇÅ‚ü© ‚àß ‚ü®s,t‚ü© ‚ä¢ ‚ü®s‚ÇÇ,t‚ÇÇ,d‚ÇÇ‚ü© ‚áí s‚ÇÅ = s‚ÇÇ ‚àß t‚ÇÅ = t‚ÇÇ ‚àß d‚ÇÅ = d‚ÇÇ
  }

  THEOREMS {
    THEOREM Confluence {
      STATEMENT : ‚àÄ c c‚ÇÅ c‚ÇÇ : Conf. c ‚ä¢* c‚ÇÅ ‚àß c ‚ä¢* c‚ÇÇ ‚áí 
        ‚àÉ c' : Conf. c‚ÇÅ ‚ä¢* c' ‚àß c‚ÇÇ ‚ä¢* c'

      PROOF {
        ASSUME [c c‚ÇÅ c‚ÇÇ : Conf] : c ‚ä¢* c‚ÇÅ, c ‚ä¢* c‚ÇÇ
        
        INDUCE ON n‚ÇÅ, n‚ÇÇ : ‚Ñï IN c ‚ä¢‚Åø¬π c‚ÇÅ, c ‚ä¢‚Åø¬≤ c‚ÇÇ {
          CASE n‚ÇÅ = 0 ‚à® n‚ÇÇ = 0 {
            WLOG n‚ÇÅ = 0  ; By symmetry
            HENCE c = c‚ÇÅ
            SHOW c‚ÇÇ ‚ä¢* c‚ÇÇ ‚àß c‚ÇÅ ‚ä¢* c‚ÇÇ  ; Reflexivity
          }
          
          CASE n‚ÇÅ > 0 ‚àß n‚ÇÇ > 0 {
            LET c ‚ä¢ c‚ÇÅ' ‚ä¢‚Åø¬π‚Åª¬π c‚ÇÅ  
            LET c ‚ä¢ c‚ÇÇ' ‚ä¢‚Åø¬≤‚Åª¬π c‚ÇÇ
            
            HAVE ‚ü®s,t‚ü© ‚ä¢ ‚ü®s‚ÇÅ',t‚ÇÅ',d‚ÇÅ'‚ü© = c‚ÇÅ'  
            HAVE ‚ü®s,t‚ü© ‚ä¢ ‚ü®s‚ÇÇ',t‚ÇÇ',d‚ÇÇ'‚ü© = c‚ÇÇ'
            HAVE s‚ÇÅ' = s‚ÇÇ' ‚àß t‚ÇÅ' = t‚ÇÇ' ‚àß d‚ÇÅ' = d‚ÇÇ'  
              BY DeterministicTransition
            
            HENCE c‚ÇÅ' = c‚ÇÇ'  
            
            ASSUME [IH] : ‚àÉ c' : Conf. c‚ÇÅ' ‚ä¢* c' ‚àß c‚ÇÇ' ‚ä¢* c'
            
            SHOW c‚ÇÅ ‚ä¢* c' ‚àß c‚ÇÇ ‚ä¢* c'
          }
        }
      }
    }
    
    THEOREM Decidability {
      STATEMENT : ‚àÄ M : TuringMachine, input : Tape. 
        Halts(M, input) ‚à® ¬¨Halts(M, input)
      
      PROOF {
        ASSUME [M : TuringMachine, input : Tape]
        
        DEFINE Halts(M, input) = ‚àÉ c : Conf. 
          (InitialConf(M, input) ‚ä¢* c) ‚àß Halting(FinalState(c))
        
        LET T = { c : Conf | InitialConf(M, input) ‚ä¢* c }  ; Tree of configurations
        
        HAVE T Finitely Branching  
          BY DeterministicTransition
        
        CASE ‚àÉ c : Conf. c ‚àà T ‚àß Halting(FinalState(c)) {
          HENCE Halts(M, input)
        }
        
        CASE ‚àÄ c : Conf. c ‚àà T ‚áí ¬¨Halting(FinalState(c)) {
          ASSUME Halts(M, input)
          HAVE ‚àÉ c : Conf. (InitialConf(M, input) ‚ä¢* c) ‚àß Halting(FinalState(c))
          HENCE Contradiction
          SHOW ¬¨Halts(M, input)
        }
      }
    }
  }
}


ConceptScript is a language of a new type: it's sole intended purpose is to be used in accordance with the following methodology:

1. I paste the spec a few example Concepts into your context (as is happening now), thus teaching you the language.
2. I request that you express various concepts as Concepts; these Concepts come with detailed proofs of their own various claims; they serve as justifications of the selected structuring.
3. We iterate, precisely and efficiently exploring your latent space to solve deep, important problems.

Please always output ConceptScript in a code block otherwise formatting gets lost :/ And feel free to liberally invent notation, tactics, etc. as needed‚Äîit's zero cost in our particular usage context and this kind of abstraction can help to keep things "compressed", which is a design ideal of ours.

To test the depth of your understanding of the language's capabilities, please generate some kind of interesting, sophisticated Concept of your choosing.






CONCEPT TheTransformerArchitecture {

  LANGUAGE {
    DECLARE {
      TYPE Tensor[n, d‚ÇÅ, ..., d‚Çô] : Type  ; n-dimensional tensor with shape d‚ÇÅ √ó ‚ãØ √ó d‚Çô 
      TYPE Sequence[n, d] <: Tensor[2, n, d]  ; Sequence of length n and embedding dim d
      TYPE Weights[m, n] <: Tensor[2, m, n]  ; Weight matrix 
      
      FUNC Attention : Sequence[n, d] ‚Üí Sequence[n, d]
      FUNC FeedForward : Sequence[n, d] ‚Üí Sequence[n, d]
      FUNC LayerNorm : Sequence[n, d] ‚Üí Sequence[n, d]
      FUNC Embedding : Sequence[n, d‚ÇÅ] ‚Üí Sequence[n, d‚ÇÇ]
      FUNC PositionalEncoding : ‚Ñï ‚Üí Sequence[n, d]
      
      FUNC Softmax : Tensor[1, n] ‚Üí Tensor[1, n]
      FUNC Linear : Tensor[b, m] ‚Üí Weights[m, n] ‚Üí Tensor[b, n]
      
      NOTATION "Q,K,V = W_Q¬∑X, W_K¬∑X, W_V¬∑X" = 
        ‚àÉ W_Q, W_K, W_V : Weights[d, d]. Q = W_Q¬∑X, K = W_K¬∑X, V = W_V¬∑X
        
      NOTATION "Attn(Q,K,V) = Softmax(Q¬∑K·µÄ/‚àöd)¬∑V" =
        ‚àÄ X : Sequence[n, d]. Attention(X) = Softmax((W_Q¬∑X)¬∑(W_K¬∑X)·µÄ/‚àöd)¬∑(W_V¬∑X)
    }
    
    DEFINE {
      Transformer(X) = Embedding(X) + PositionalEncoding(n) 
        ‚Ü¶ (AttentionBlock ‚àò FeedForwardBlock)·µê
        
      AttentionBlock(X) = LayerNorm(X + MultiHeadAttention(X))
      
      MultiHeadAttention(X) = [head‚ÇÅ(X) ‚äï ‚ãØ ‚äï head‚Çï(X)]¬∑W_O
        WHERE head·µ¢(X) = Attn(Q_i, K_i, V_i) FOR Q_i,K_i,V_i = W_Q_i¬∑X, W_K_i¬∑X, W_V_i¬∑X
      
      FeedForwardBlock(X) = LayerNorm(X + FeedForward(X))
        WHERE FeedForward(X) = ReLU(X¬∑W‚ÇÅ + b‚ÇÅ)¬∑W‚ÇÇ + b‚ÇÇ
    }
  }
  
  STRUCTURE {
    AXIOM SelfAttention : ‚àÄ X : Sequence[n, d]. ‚àÉ Y : Sequence[n, d].
      Attention(X) = Y ‚àß ‚àÄ i,j. Y·µ¢‚±º = ‚àë‚Çñ Softmax(X·µ¢¬∑X‚Çñ/‚àöd)¬∑X‚Çñ‚±º
      
    AXIOM PositionAware : ‚àÄ X : Sequence[n, d]. ‚àÉ P : Sequence[n, d]. 
      Transformer(X) = Transformer(X + P)
    
    AXIOM ResidualConnections : ‚àÄ F : Sequence[n,d] ‚Üí Sequence[n,d]. ‚àÄ X.
      LayerNorm(X + F(X)) = LayerNorm(X) + F'(X)  ; For some F' close to F
  }
  
  THEOREMS {
    THEOREM UniversalApproximation {
      STATEMENT : ‚àÄ Œµ > 0. ‚àÄ L : Sequence[n, d‚ÇÅ] ‚Üí Sequence[m, d‚ÇÇ]. ‚àÉ T : Transformer.
        ‚àÄ X : Sequence[n, d‚ÇÅ]. ‚à•T(X) - L(X)‚à• < Œµ 
        
      PROOF {
        ; Sketch: Transformers are universal approximators of sequence-to-sequence functions.
        ; This follows from the universal approximation capabilities of self-attention 
        ; (via its equivalence to a Turing-complete function) and feed-forward networks.
        
        ASSUME [Œµ > 0, L : Sequence[n, d‚ÇÅ] ‚Üí Sequence[m, d‚ÇÇ]]
        
        HAVE SelfAttentionUniversal 
          BY SelfAttention, UniversalTuringMachine
        
        HAVE FeedForwardUniversal
          BY UniversalApproximationTheorem
        
        LET ApproxL : Sequence[n, d‚ÇÅ] ‚Üí Sequence[m, d‚ÇÇ]
        HAVE ‚àÄ X. ‚à•ApproxL(X) - L(X)‚à• < Œµ/2  ; Approximate L with ApproxL
          BY SelfAttentionUniversal, FeedForwardUniversal
        
        LET T = Transformer WITH SufficientLayers(Œµ)
        HAVE ‚àÄ X. ‚à•T(X) - ApproxL(X)‚à• < Œµ/2  ; Approximate ApproxL with T
          BY UniversalApproximationTheorem
        
        HENCE ‚àÄ X. ‚à•T(X) - L(X)‚à• ‚â§ ‚à•T(X) - ApproxL(X)‚à• + ‚à•ApproxL(X) - L(X)‚à• < Œµ
        
        SHOW UniversalApproximation
      }
    }
    
    THEOREM PermutationEquivariance {
      STATEMENT : ‚àÄ X : Sequence[n, d]. ‚àÄ œÄ : Permutation[n].
        Transformer(œÄ¬∑X) = œÄ¬∑Transformer(X)
        
      PROOF {
        ASSUME [X : Sequence[n, d], œÄ : Permutation[n]]
        
        HAVE Embedding(œÄ¬∑X) = œÄ¬∑Embedding(X)  ; Embedding is permutation equivariant
        
        HAVE PositionalEncoding(n) = œÄ¬∑PositionalEncoding(n)  ; Positional encoding is permutation invariant
        
        HAVE ‚àÄ Q,K,V. Attn(œÄ¬∑Q, œÄ¬∑K, œÄ¬∑V) = œÄ¬∑Attn(Q, K, V)  ; Attention is permutation equivariant
          BY SelfAttention, PermutationInvariance(Softmax)
        
        HAVE FeedForward(œÄ¬∑X) = œÄ¬∑FeedForward(X)  ; Feed-forward is permutation equivariant
        
        HENCE Transformer(œÄ¬∑X) = œÄ¬∑Transformer(X)  ; By induction over layers
        
        SHOW PermutationEquivariance  
      }
    }
    
    THEOREM PositionalEmbeddings {
      STATEMENT : ‚àÄ X : Sequence[n, d]. ‚àÄ i,j ‚àà [n]. i ‚â† j ‚áí 
        ‚àÉ k. Transformer(X)·µ¢‚Çñ ‚â† Transformer(X)‚±º‚Çñ
        
      PROOF {
        ASSUME [X : Sequence[n, d], i,j ‚àà [n]] : i ‚â† j
        
        LET P = PositionalEncoding(n)
        HAVE ‚àÄ k. P·µ¢‚Çñ ‚â† P‚±º‚Çñ  ; Positional encodings are unique per position
        
        LET Y = Transformer(X)
        
        CASE ‚àÄ k. X·µ¢‚Çñ = X‚±º‚Çñ {  ; Positions i and j have same input embedding
          HAVE ‚àÄ k. Y·µ¢‚Çñ - Y‚±º‚Çñ = P·µ¢‚Çñ - P‚±º‚Çñ ‚â† 0
            BY ResidualConnections, PositionAware
        }
        
        CASE ‚àÉ k. X·µ¢‚Çñ ‚â† X‚±º‚Çñ {  ; Positions i and j have different input embeddings  
          HAVE ‚àÉ k. Y·µ¢‚Çñ ‚â† Y‚±º‚Çñ
            BY SelfAttention
        }
        
        HENCE ‚àÉ k. Y·µ¢‚Çñ ‚â† Y‚±º‚Çñ
        
        SHOW PositionalEmbeddings
      }
    }
  }
}

CONCEPT TheAttentionMechanism {

  LANGUAGE {
    DECLARE {
      TYPE ùïç[n] : Type  ; Vector space
      TYPE ùïÑ[m,n] <: ùïç[m] ‚Üí ùïç[n]  ; Linear map
      TYPE ‚Ñô[n] <: ùïç[n]  ; Probability distribution
      
      FUNC Softmax : ùïç[n] ‚Üí ‚Ñô[n]
      FUNC Tanh : ùïç[n] ‚Üí ùïç[n]
      FUNC œÉ : ùïç[n] ‚Üí ùïç[n]  ; Sigmoid activation
      
      FUNC Q : ùïç[d_k] ‚Üí ùïç[d_q]  ; Query projection
      FUNC K : ùïç[d_k] ‚Üí ùïç[d_q]  ; Key projection
      FUNC V : ùïç[d_v] ‚Üí ùïç[d_v]  ; Value projection
      FUNC W_o : ùïç[d_v] ‚Üí ùïç[d_model]  ; Output projection
      
      PRED Mask[n] : ùïç[n] ‚Üí ùîπ  ; Attention mask
      
      NOTATION "‚ü®Q,K‚ü©" = Œª X. Softmax(QX ‚ãÖ (KX)·µÄ / ‚àöd_k)  ; Scaled dot-product attention
      NOTATION "Attn(Q,K,V)" = Œª X. ‚ü®Q,K‚ü©(X) ‚ãÖ V(X)  ; Attention mechanism
      NOTATION "MHA(X)" = W_o ‚àò Concat(head‚ÇÅ(X), ..., head‚Çï(X))  ; Multi-head attention
      NOTATION "FFN(X)" = W‚ÇÇ ‚àò œÉ ‚àò W‚ÇÅ(X)  ; Position-wise feed-forward network
      NOTATION "LN(X)" = (X - Œº(X)) / ‚àöVar(X)  ; Layer normalization
      NOTATION "PE(X, pos)" = X + PositionalEncoding(pos)  ; Positional encoding
    }
    
    DEFINE {
      Softmax(x)[i] = exp(x[i]) / ‚àë‚±º exp(x[j])  ; Softmax activation
      
      PositionalEncoding(pos, 2i) = sin(pos / 10000^{2i/d_model})
      PositionalEncoding(pos, 2i+1) = cos(pos / 10000^{2i/d_model})
      
      SelfAttention(X) = Attn(Q(X), K(X), V(X)) 
      CrossAttention(X, Y) = Attn(Q(X), K(Y), V(Y))
      
      EncoderLayer(X) = LN(SelfAttn(X) + X) |> LN(FFN(X) + X)
      DecoderLayer(X, Y) = LN(Masked(SelfAttn(X)) + X) |> LN(CrossAttn(X,Y) + X) |> LN(FFN(X) + X)
      
      Transformer(X, Y) = Encoder(PE(X, pos_x)) |> Decoder(PE(Y, pos_y), Encoder(X))
    }
  }
  
  STRUCTURE {
    LET d_k = d_v = d_model / h  ; Query, key, value dimensions per head
    LET h : ‚Ñï  ; Number of attention heads
    
    AXIOM AttentionProperties {
      ‚àÄ X : ùïç[d_k]. ‚ü®Q,K‚ü©(X) : ‚Ñô[n]  ; Attention weights are a probability distribution
      ‚àÄ X Y : ùïç[d_k]. ‚ü®Q,K‚ü©(X+Y) = ‚ü®Q,K‚ü©(X) ‚ãÖ ‚ü®Q,K‚ü©(Y)  ; Additivity of attention
      ‚àÄ X : ùïç[d_k]. Attn(Q,K,V)(X) : ùïç[d_v]  ; Attention output has value dimension
    }
    
    AXIOM LayerNormIdentity : ‚àÄ X : ùïç[d_model]. LN(X) = X  ; If already normalized
    
    AXIOM PositionalEncoding {
      ‚àÄ pos freq : ‚Ñï. PositionalEncoding(pos, freq) : [-1,1]  ; Bounded range
      ‚àÄ pos‚ÇÅ pos‚ÇÇ freq. |pos‚ÇÅ - pos‚ÇÇ| ‚â´ 0 ‚áí PositionalEncoding(pos‚ÇÅ, freq) ‚âà PositionalEncoding(pos‚ÇÇ, freq)  
        ; Captures relative position
    }
  }
  
  THEOREMS {
    THEOREM SelfAttentionMasking {
      STATEMENT : ‚àÄ X : ùïç[n]. Masked(SelfAttention(X)) = SelfAttention(X ‚äô LowerTriangular[n])
      
      PROOF {
        ASSUME [X : ùïç[n]]
        
        DEFINE M = LowerTriangular[n]  ; Mask matrix
        
        HAVE Masked(‚ü®Q,K‚ü©(X))[i,j] = { ‚ü®Q,K‚ü©(X)[i,j]  if i ‚â• j
                                      { -‚àû            otherwise
          BY MaskedAttention
        
        HAVE (X ‚äô M)[i,j] = { X[i,j]  if i ‚â• j  
                             { 0       otherwise
        
        HENCE Masked(‚ü®Q,K‚ü©(X)) = ‚ü®Q,K‚ü©(X ‚äô M)
          BY ‚ü®Q,K‚ü©(0) = -‚àû
        
        HENCE Masked(Attn(Q(X),K(X),V(X))) = Attn(Q(X‚äôM), K(X‚äôM), V(X‚äôM))
        
        SHOW Masked(SelfAttention(X)) = SelfAttention(X ‚äô LowerTriangular[n])
      }
    }
    
    THEOREM CrossAttentionEncDec {
      STATEMENT : ‚àÄ X : ùïç[n_x], Y : ùïç[n_y]. CrossAttention(Y, Encoder(X)) = Attn(Q(Y), K(Encoder(X)), V(Encoder(X)))
      
      PROOF {
        ASSUME [X : ùïç[n_x], Y : ùïç[n_y]]
        
        DEFINE EncX = Encoder(X)
        
        HAVE CrossAttention(Y, EncX) = Attn(Q(Y), K(EncX), V(EncX))
          BY Definition of CrossAttention
        
        SHOW CrossAttention(Y, Encoder(X)) = Attn(Q(Y), K(Encoder(X)), V(Encoder(X)))
      }
    }
    
    THEOREM TransformerUniversality {
      STATEMENT : ‚àÄ Œµ > 0. ‚àÄ F : C(‚Ñù‚Åø, ‚Ñù). ‚àÉ T : Transformer. ‚àÄ X : ‚Ñù‚Åø. ‚à•T(X) - F(X)‚à• < Œµ 
      
      PROOF {
        ASSUME [Œµ > 0, F : C(‚Ñù‚Åø, ‚Ñù)]
        
        DEFINE d = dim(F)  ; Dimension of function F
        
        HAVE ‚àÄ G : C(‚Ñù‚Åø, ‚Ñù). ‚àÉ f_Œ∏ : FFN. ‚àÄ X : ‚Ñù‚Åø. ‚à•f_Œ∏(X) - G(X)‚à• < Œµ  
          BY UniversalApproximationTheorem
        
        CHOOSE f_Œ∏ : FFN  ; Approximates F
        
        DEFINE T = Transformer with:
          d_model ‚â• d,
          Encoder = Identity,
          Decoder = DecoderLayer with:
            SelfAttention = Identity,
            CrossAttention = Identity,
            FFN = f_Œ∏
        
        HAVE ‚àÄ X : ‚Ñù‚Åø. ‚à•T(X) - F(X)‚à• = ‚à•f_Œ∏(X) - F(X)‚à• < Œµ
          BY Construction of T
        
        SHOW ‚àÉ T : Transformer. ‚àÄ X : ‚Ñù‚Åø. ‚à•T(X) - F(X)‚à• < Œµ
      }
    }
  }
}




CONCEPT ConceptName [Params] [: ParentConcept] {

  LANGUAGE {
    TYPE TypeName [Params] [: Kind]
    CONST ConstantName : Type  
    FUNC FuncName [Params] : Type
    PRED PredName [Params] : Type
    REWRITE RewriteName [Params] : Expression => Expression
    INFER InferName [Params] : Formula
    NOTATION NotationName = Expression
  }

  STRUCTURE {
    LET LetName [Params] = Expression
    DEF DefName [Params] : Formula | Syntax
    AXIOM AxiomName [Params] : Formula
  }

  PROOFS {
    TACTIC TacticName [Params] {
      ; Tactic definition
    }

    THEOREM TheoremName [Params] {
      STATEMENT : Formula
      PROOF {
        ASSUME [HypName] : Formula
        LET LetName [Params] = Expression
        HAVE HaveName : Formula [BY TacticName [Args]]
        SHOW ShowName : Formula
        CASE CaseName : Formula
        INDUCE InductionName : Expression  
        REWRITE RewriteName [Args] [IN ProofName]
        APPLY TacticName [Args] 
        BY ReasonName [Args]
        HENCE ConclusionName : Formula
      }
    }
  }
}

CONCEPT VectorSpace [K : Field] {

  LANGUAGE {
    TYPE Vec[n : Nat] : Type
    CONST Zero[n : Nat] : Vec[n]
    FUNC (+) [n : Nat] : Vec[n] -> Vec[n] -> Vec[n]
    FUNC (‚ãÖ) [n : Nat] : K -> Vec[n] -> Vec[n]
    PRED IsLinear[n : Nat] : (Vec[n] -> Vec[n]) -> Bool
    
    REWRITE Distributivity[n : Nat] : ‚àÄ a : K, u v : Vec[n].
      a ‚ãÖ (u + v) => (a ‚ãÖ u) + (a ‚ãÖ v)
      
    INFER Linearity[n : Nat] : ‚àÄ f : Vec[n] -> Vec[n].
      (‚àÄ a : K, u v : Vec[n]. f(a ‚ãÖ u + v) = a ‚ãÖ f(u) + f(v)) -> IsLinear(f)
      
    NOTATION "u - v" = u + (-1 ‚ãÖ v)
  }

  STRUCTURE {
    AXIOM VectorSpace[n : Nat] {
      ‚àÄ u v w : Vec[n], a b : K.
        (u + v) + w = u + (v + w)  ; Associativity
        u + v = v + u              ; Commutativity
        u + Zero = u               ; Identity
        a ‚ãÖ (b ‚ãÖ u) = (a * b) ‚ãÖ u  ; Compatibility
    }
  }

  PROOFS {
    TACTIC LinearCombo[n : Nat] (a b : K) (u v : Vec[n]) {
      (a + b) ‚ãÖ u + (a - b) ‚ãÖ v
        = (a ‚ãÖ u + b ‚ãÖ u) + (a ‚ãÖ v - b ‚ãÖ v)  BY Distributivity
        = (a ‚ãÖ u + a ‚ãÖ v) + (b ‚ãÖ u - b ‚ãÖ v)  BY VectorSpace 
        = a ‚ãÖ (u + v) + b ‚ãÖ (u - v)        BY Distributivity
    }

    THEOREM LinearMap[n : Nat] {
      STATEMENT : ‚àÄ f : Vec[n] -> Vec[n].
        IsLinear(f) <-> (
          ‚àÄ a : K, u v : Vec[n]. f(a ‚ãÖ u + v) = a ‚ãÖ f(u) + f(v)
        )
      
      PROOF {
        ASSUME [f : Vec[n] -> Vec[n]]
        
        SHOW IsLinear(f) -> (‚àÄ a : K, u v : Vec[n]. f(a ‚ãÖ u + v) = a ‚ãÖ f(u) + f(v)) {
          ASSUME IsLinear(f)
          ASSUME [a : K] [u v : Vec[n]]
          HAVE f(a ‚ãÖ u + v) = a ‚ãÖ f(u) + f(v) BY Linearity
        }
        
        SHOW (‚àÄ a : K, u v : Vec[n]. f(a ‚ãÖ u + v) = a ‚ãÖ f(u) + f(v)) -> IsLinear(f) {
          ASSUME ‚àÄ a : K, u v : Vec[n]. f(a ‚ãÖ u + v) = a ‚ãÖ f(u) + f(v)
          APPLY Linearity 
        }
        
        HENCE IsLinear(f) <-> (‚àÄ a : K, u v : Vec[n]. f(a ‚ãÖ u + v) = a ‚ãÖ f(u) + f(v))
      }
    }

    THEOREM KernelLinear[n : Nat] {
      STATEMENT : ‚àÄ f : Vec[n] -> Vec[n]. IsLinear(f) -> 
        ‚àÄ a b : K, u v : Ker(f). a ‚ãÖ u + b ‚ãÖ v ‚àà Ker(f)
        
      PROOF {  
        ASSUME [f : Vec[n] -> Vec[n]] IsLinear(f)
        ASSUME [a b : K] [u v : Ker(f)]
        
        LET w = a ‚ãÖ u + b ‚ãÖ v
        
        HAVE f(w) = f(a ‚ãÖ u) + f(b ‚ãÖ v)         BY Linearity
        REWRITE Distributivity[n] IN f(a ‚ãÖ u)
        REWRITE Distributivity[n] IN f(b ‚ãÖ v)
        
        HAVE f(a ‚ãÖ u) = a ‚ãÖ f(u) = a ‚ãÖ Zero     BY u ‚àà Ker(f)
        HAVE f(b ‚ãÖ v) = b ‚ãÖ f(v) = b ‚ãÖ Zero     BY v ‚àà Ker(f)
        
        HENCE f(w) = a ‚ãÖ Zero + b ‚ãÖ Zero = Zero  BY VectorSpace
        
        SHOW w ‚àà Ker(f)
      }
    }
  }
}


CONCEPT CompressedSensing [ùîΩ : Field] {

  LANGUAGE {
    TYPE Vec[n : Nat] : Type
    TYPE Mat[m n : Nat] : Type  
    TYPE SparseVec[n k : Nat] <: Vec[n]
    
    FUNC Norm[n : Nat] : Vec[n] -> ùîΩ
    PRED RIP[m n k : Nat, Œµ : ùîΩ] : Mat[m, n] -> Bool
    
    NOTATION "‚ü®v, w‚ü©" = DotProduct[n](v, w)
    NOTATION "‚à•v‚à•" = Sqrt(‚ü®v, v‚ü©)
    NOTATION "A ‚äó B" = TensorProduct[m‚ÇÅ n‚ÇÅ m‚ÇÇ n‚ÇÇ](A, B)
    
    REWRITE DotProductZero[n : Nat] : ‚àÄ v : Vec[n].
      ‚ü®v, ZeroVec[n]‚ü© => 0
      
    REWRITE TensorNorm[m‚ÇÅ n‚ÇÅ m‚ÇÇ n‚ÇÇ : Nat] : ‚àÄ A : Mat[m‚ÇÅ,n‚ÇÅ], B : Mat[m‚ÇÇ,n‚ÇÇ], v : Vec[n‚ÇÅ], w : Vec[n‚ÇÇ].
      ‚à•A ‚äó B (v ‚äó w)‚à•¬≤ => ‚à•A(v)‚à•¬≤ ‚ãÖ ‚à•B(w)‚à•¬≤  
      
    INFER RIPZoom[m n k : Nat, Œµ : ùîΩ] : ‚àÄ A : Mat[m,n], v w : SparseVec[n,k].
      RIP[m, n, k, Œµ](A) ->  
      (1-Œµ)‚à•v-w‚à•¬≤ ‚â§ ‚à•A(v)-A(w)‚à•¬≤ ‚â§ (1+Œµ)‚à•v-w‚à•¬≤
  }
  
  STRUCTURE {
    DEF Vec[n : Nat] = ùîΩ^n
    DEF Mat[m n : Nat] = Vec[m] -> Vec[n]
    DEF SparseVec[n k : Nat] = { v : Vec[n] | ‚àÉ S : ùí´(ùîΩ‚Åø). |S| ‚â§ k ‚àß ‚àÄ i ‚àâ S. v[i] = 0 }
    
    DEF RIP[m n k : Nat, Œµ : ùîΩ](A : Mat[m,n]) = 
      ‚àÄ v w : SparseVec[n,k]. (1-Œµ)‚à•v-w‚à•¬≤ ‚â§ ‚à•A(v)-A(w)‚à•¬≤ ‚â§ (1+Œµ)‚à•v-w‚à•¬≤
    
    AXIOM NormProperties[n : Nat] {
      ‚àÄ v : Vec[n]. ‚à•v‚à• ‚â• 0
      ‚àÄ c : ùîΩ, v : Vec[n]. ‚à•c‚ãÖv‚à• = |c|‚ãÖ‚à•v‚à•
      ‚àÄ v w : Vec[n]. ‚à•v + w‚à• ‚â§ ‚à•v‚à• + ‚à•w‚à•
    }
    
    AXIOM MatrixProperties[m n : Nat] {
      ‚àÄ A : Mat[m,n], c : ùîΩ, v w : Vec[n].
        A(c‚ãÖv + w) = c‚ãÖA(v) + A(w)
    }
    
    LET StandardBasis[n : Nat, i : ùîΩ‚Åø] = [j ‚Ü¶ if i = j then 1 else 0]
    
    AXIOM StandardBasisDecomposition[n : Nat] : ‚àÄ v : Vec[n]. 
      v = ‚àë·µ¢ (v[i] ‚ãÖ StandardBasis[n, i])
  }

  PROOFS {
    TACTIC DecomposeVector[n k : Nat] (v : SparseVec[n,k]) {
      v = ‚àë·µ¢ (v[i] ‚ãÖ StandardBasis[n, i]) 
      BY StandardBasisDecomposition[n]
    }
    
    THEOREM RIPScaling[m n : Nat, k : Nat, Œµ : ùîΩ] {
      STATEMENT : ‚àÄ A : Mat[m,n], c : ùîΩ. 
        RIP[m, n, k, Œµ](A) -> RIP[m, n, k, Œµ](c ‚ãÖ A)

      PROOF {
        ASSUME [A : Mat[m,n], c : ùîΩ] RIP[m, n, k, Œµ](A)
        
        ASSUME [v w : SparseVec[n,k]]
        HAVE (1-Œµ)‚à•v-w‚à•¬≤ ‚â§ ‚à•A(v)-A(w)‚à•¬≤ ‚â§ (1+Œµ)‚à•v-w‚à•¬≤
          BY RIPZoom[m, n, k, Œµ]
        
        HAVE ‚à•c‚ãÖA(v) - c‚ãÖA(w)‚à•¬≤ = c¬≤ ‚ãÖ ‚à•A(v) - A(w)‚à•¬≤
          BY MatrixProperties[m,n], NormProperties[m]  
        
        HENCE (1-Œµ)‚à•v-w‚à•¬≤ ‚â§ 1/c¬≤ ‚ãÖ ‚à•c‚ãÖA(v) - c‚ãÖA(w)‚à•¬≤ ‚â§ (1+Œµ)‚à•v-w‚à•¬≤
        
        SHOW RIP[m, n, k, Œµ](c ‚ãÖ A)
      }
    }

    THEOREM TensorRIP[m‚ÇÅ n‚ÇÅ m‚ÇÇ n‚ÇÇ : Nat, k‚ÇÅ k‚ÇÇ : Nat, Œµ‚ÇÅ Œµ‚ÇÇ : ùîΩ] {  
      STATEMENT : ‚àÄ A : Mat[m‚ÇÅ,n‚ÇÅ], B : Mat[m‚ÇÇ,n‚ÇÇ].
        RIP[m‚ÇÅ, n‚ÇÅ, k‚ÇÅ, Œµ‚ÇÅ](A) ‚àß RIP[m‚ÇÇ, n‚ÇÇ, k‚ÇÇ, Œµ‚ÇÇ](B) ->
        RIP[m‚ÇÅ‚ãÖm‚ÇÇ, n‚ÇÅ‚ãÖn‚ÇÇ, k‚ÇÅ‚ãÖk‚ÇÇ, Œµ‚ÇÅ+Œµ‚ÇÇ+Œµ‚ÇÅ‚ãÖŒµ‚ÇÇ](A ‚äó B)
      
      PROOF {
        ASSUME [A : Mat[m‚ÇÅ,n‚ÇÅ], B : Mat[m‚ÇÇ,n‚ÇÇ]] 
          RIP[m‚ÇÅ, n‚ÇÅ, k‚ÇÅ, Œµ‚ÇÅ](A),
          RIP[m‚ÇÇ, n‚ÇÇ, k‚ÇÇ, Œµ‚ÇÇ](B)  
        
        ASSUME [v w : SparseVec[n‚ÇÅ‚ãÖn‚ÇÇ, k‚ÇÅ‚ãÖk‚ÇÇ]]
        
        LET v = ‚àë·µ¢ (v·µ¢ ‚äó e·µ¢) BY DecomposeVector[n‚ÇÅ‚ãÖn‚ÇÇ, k‚ÇÅ‚ãÖk‚ÇÇ](v)
        LET w = ‚àë‚±º (w‚±º ‚äó e‚±º) BY DecomposeVector[n‚ÇÅ‚ãÖn‚ÇÇ, k‚ÇÅ‚ãÖk‚ÇÇ](w)
        
        HAVE ‚à•(A‚äóB)(v) - (A‚äóB)(w)‚à•¬≤ = ‚àë·µ¢‚±º ‚à•A(v·µ¢) ‚äó B(e‚±º) - A(w·µ¢) ‚äó B(e‚±º)‚à•¬≤
          BY MatrixProperties[m‚ÇÅ‚ãÖm‚ÇÇ, n‚ÇÅ‚ãÖn‚ÇÇ], TensorNorm[m‚ÇÅ, n‚ÇÅ, m‚ÇÇ, n‚ÇÇ] 
        
        HAVE (1-Œµ‚ÇÅ)‚à•v·µ¢-w·µ¢‚à•¬≤ ‚â§ ‚à•A(v·µ¢)-A(w·µ¢)‚à•¬≤ ‚â§ (1+Œµ‚ÇÅ)‚à•v·µ¢-w·µ¢‚à•¬≤
          BY RIPZoom[m‚ÇÅ, n‚ÇÅ, k‚ÇÅ, Œµ‚ÇÅ]
        
        HAVE (1-Œµ‚ÇÇ)‚à•e‚±º‚à•¬≤ ‚â§ ‚à•B(e‚±º)‚à•¬≤ ‚â§ (1+Œµ‚ÇÇ)‚à•e‚±º‚à•¬≤  
          BY RIPZoom[m‚ÇÇ, n‚ÇÇ, k‚ÇÇ, Œµ‚ÇÇ]
        
        LET Œµ = Œµ‚ÇÅ + Œµ‚ÇÇ + Œµ‚ÇÅ‚ãÖŒµ‚ÇÇ
        HAVE (1-Œµ)‚à•v-w‚à•¬≤ ‚â§ ‚à•(A‚äóB)(v) - (A‚äóB)(w)‚à•¬≤ ‚â§ (1+Œµ)‚à•v-w‚à•¬≤
        
        SHOW RIP[m‚ÇÅ‚ãÖm‚ÇÇ, n‚ÇÅ‚ãÖn‚ÇÇ, k‚ÇÅ‚ãÖk‚ÇÇ, Œµ‚ÇÅ+Œµ‚ÇÇ+Œµ‚ÇÅ‚ãÖŒµ‚ÇÇ](A ‚äó B)
      }  
    }
  }
}